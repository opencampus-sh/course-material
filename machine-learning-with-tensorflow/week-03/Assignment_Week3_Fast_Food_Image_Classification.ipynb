{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment Week 3 - \"Large\" Datasets and Data Augmentation"
      ],
      "metadata": {
        "id": "Bte1ngygIzYD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVcGvEOOf5i-"
      },
      "source": [
        "## Task 1\n",
        "\n",
        "1. Download the [\"Fast Food Classification Dataset - V2\"](https://www.kaggle.com/datasets/utkarshsaxenadn/fast-food-classification-dataset/data) from Kaggle.\n",
        "\n",
        "2. Unzip and ensure that the dataset in Colab is structured as follows:\n",
        "\n",
        "```\n",
        "|\n",
        "|-- Fast Food Classification V2\n",
        "|   |-- TFRecords\n",
        "|   |-- Test\n",
        "|   |-- Train\n",
        "|   `-- Valid\n",
        "|-- sample_data\n",
        "`-- archive.zip\n",
        "```\n",
        "\n",
        "`Fast Food Classification V2` and `archive.zip` should be on the same level as the already existing `sample_data` directory from Colab. You can ignore the `TFRecords` subdirectory in the following tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5811abzgIiK"
      },
      "outputs": [],
      "source": [
        "#!/bin/bash\n",
        "!curl -L -o archive.zip https://www.kaggle.com/api/v1/datasets/download/utkarshsaxenadn/fast-food-classification-dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q archive.zip"
      ],
      "metadata": {
        "id": "SytLYfaw6GyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2\n",
        "\n",
        "1. Define the directory paths for training, validation, and test datasets.\n",
        "\n",
        "2. Apply the provided `delete_invalid_images` function to check and remove any corrupted or invalid images in each of the three dataset directories."
      ],
      "metadata": {
        "id": "-dNVt06Gz828"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_DIR = \"\" # TODO: Add the training data directory path\n",
        "VALIDATION_DIR = \"\" # TODO: Add the validation data directory path\n",
        "TEST_DIR = \"\" # TODO: Add the test data directory path"
      ],
      "metadata": {
        "id": "PgMW3wxY0BHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Define the paths to the directories\n",
        "directories = [\n",
        "    TRAINING_DIR,\n",
        "    VALIDATION_DIR,\n",
        "    TEST_DIR\n",
        "]\n",
        "\n",
        "# Define supported image file extensions\n",
        "supported_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp'}\n",
        "\n",
        "def delete_invalid_images(directory):\n",
        "    \"\"\"Goes through a directory and deletes any invalid or unsupported images.\"\"\"\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            # Check if the file has a supported extension\n",
        "            if not any(file.lower().endswith(ext) for ext in supported_extensions):\n",
        "                print(f\"Deleting unsupported file: {file_path}\")\n",
        "                os.remove(file_path)\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.load()  # Ensure the image content can be read\n",
        "                    if img.format not in [\"JPEG\", \"PNG\", \"GIF\", \"BMP\"]:\n",
        "                        raise IOError(\"Unsupported image format\")\n",
        "            except (IOError, SyntaxError, AttributeError) as e:\n",
        "                print(f\"Deleting invalid or corrupted image: {file_path}\")\n",
        "                os.remove(file_path)\n",
        "\n",
        "# Run the function for each directory\n",
        "for dir_path in directories:\n",
        "    delete_invalid_images(dir_path)\n",
        "\n",
        "print(\"Invalid and unsupported image cleanup completed.\")"
      ],
      "metadata": {
        "id": "BYsDXojA0Wm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3\n",
        "\n",
        "1. Implement a function that visualizes 3 random examples per class from the training data to get a feel for the dataset.\n",
        "\n",
        "2. Run the function multiple times to get different images from the dataset.\n",
        "\n",
        "Tip: You can use whatever Python packages you like. `opencv` and `matplotlib` might be suitable choices."
      ],
      "metadata": {
        "id": "_7IXjgBw1VW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def visualize_random_images(directory_path, num_images=3):\n",
        "    image_files = [image_file for image_file in os.listdir(directory_path)]\n",
        "\n",
        "    # TODO: Implement the rest of the function\n",
        "    # YOUR CODE STARTS HERE\n",
        "\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "    # YOUR CODE ENDS HERE\n",
        "\n",
        "class_directory_paths = os.listdir(TRAINING_DIR)\n",
        "\n",
        "for class_directory_path in class_directory_paths:\n",
        "  visualize_random_images(TRAINING_DIR + \"/\" + class_directory_path)"
      ],
      "metadata": {
        "id": "pId_My4Y1kXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4\n",
        "\n",
        "1. Choose an appropriate image size for the input images for an image classification task and set the values of the predefined constants `IMAGE_HEIGHT` and `IMAGE_WIDTH`.\n",
        "\n",
        "2. Load the training, validation and test datasets using the `image_dataset_from_directory` function shown in the Coursera course. Specifically, set appropriate values for `label_mode`, `batch_size`, `image_size` and `shuffle`. Each dataset should get a fixed `seed` of `123`.\n",
        "Checkout the documentation for details:\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory\n",
        "\n",
        "3. Briefly explain for which of the training, validation and test datasets might be important to shuffle the data and why this is important."
      ],
      "metadata": {
        "id": "psoxk096bqzM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1v8Xkxvf5jE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulnhb0H1f5jH"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "IMAGE_HEIGHT = None # TODO: Choose an appropriate image height\n",
        "IMAGE_WIDTH = None # TODO: Choose an appropriate image width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74swqB1Nf5jI"
      },
      "outputs": [],
      "source": [
        "train_images = None # TODO: Load the training dataset from the corresponding directory\n",
        "\n",
        "validation_images = None # TODO: Load the validation dataset from the corresponding directory\n",
        "\n",
        "test_images = None # TODO: Load the test dataset from the corresponding directory"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output:**  \n",
        "Found 14999 images belonging to 10 classes.  \n",
        "Found 3500 images belonging to 10 classes.  \n",
        "Found 1500 images belonging to 10 classes.  "
      ],
      "metadata": {
        "id": "tAdCBgsr1F6R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 5\n",
        "\n",
        "In this exercise you will be given a predefined model architecture (except for the data augmentation layers) that you should train using the data with and without the application of data augmentation and compare the results of the different models.\n",
        "\n",
        "1. Train the model without data augmentation for at least 30 epochs. Save a screenshot of the resulting accuracy and loss plots and judge the quality of the model. Also note the loss and accuracy of the model on the test set.\n",
        "\n",
        "2. Train the model again, this time using data augmentation for the same number of epochs as the previous model. Choose 2 to 3 data augmentation techniques (other than rescaling) that might be suitable for the given dataset, and briefly explain why. Compare the training and model quality of the two models.\n",
        "\n",
        "Take a look at this tutorial for an overview of (some) data augmentation techniques:\n",
        "https://www.tensorflow.org/tutorials/images/data_augmentation"
      ],
      "metadata": {
        "id": "aAwfSf2mbwZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Add data augmentation layers\n",
        "data_augmentation_layers = tf.keras.Sequential([\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "JVa85yLAG7y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMG2AOP_f5jK"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input((IMAGE_HEIGHT, IMAGE_WIDTH, 3)),\n",
        "    tf.keras.layers.Rescaling(1/255),\n",
        "    # data_augmentation_layers,\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjY9KixKf5jM"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images,\n",
        "                    validation_data=validation_images,\n",
        "                    epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the model training history\n",
        "def plot_training_history(history):\n",
        "    # Extracting accuracy and loss from the history object\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    # Setting up the number of epochs for the x-axis\n",
        "    epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "    # Plotting training and validation accuracy\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plotting training and validation loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history)"
      ],
      "metadata": {
        "id": "PHLYrEAKOV-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate loss and accuracy on the test set\n",
        "test_loss, test_acc = model.evaluate(test_images)\n",
        "print(f\"Test Accuracy: {test_acc} | Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "id": "66z0TJ7wPWO8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}