{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bte1ngygIzYD"
      },
      "source": [
        "# Assignment Week 3 - \"Large\" Datasets and Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVcGvEOOf5i-"
      },
      "source": [
        "## Task 1\n",
        "\n",
        "Run the following two code cells to:\n",
        "\n",
        "1. Download the [\"Fast Food Classification Dataset - V2\"](https://www.kaggle.com/datasets/utkarshsaxenadn/fast-food-classification-dataset/data) from Kaggle.\n",
        "\n",
        "2. Unzip the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5811abzgIiK"
      },
      "outputs": [],
      "source": [
        "#!/bin/bash\n",
        "!curl -L -o archive.zip https://www.kaggle.com/api/v1/datasets/download/utkarshsaxenadn/fast-food-classification-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SytLYfaw6GyZ"
      },
      "outputs": [],
      "source": [
        "!unzip -q archive.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ensure that the dataset is structured as follows (in Colab):\n",
        "\n",
        "```\n",
        "|\n",
        "|-- Fast Food Classification V2\n",
        "|   |-- TFRecords\n",
        "|   |-- Test\n",
        "|   |-- Train\n",
        "|   `-- Valid\n",
        "|-- sample_data\n",
        "`-- archive.zip\n",
        "```\n",
        "\n",
        "`Fast Food Classification V2` and `archive.zip` should be on the same level as the already existing `sample_data` directory from Colab. You can ignore the `TFRecords` subdirectory in the following tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dNVt06Gz828"
      },
      "source": [
        "## Task 2\n",
        "\n",
        "1. Define the directory paths for training, validation, and test datasets.\n",
        "\n",
        "2. Apply the provided `delete_invalid_images` function to check and remove any corrupted or invalid images in each of the three dataset directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgMW3wxY0BHl"
      },
      "outputs": [],
      "source": [
        "TRAINING_DIRECTORY = ... # TODO: Specify the training data directory path\n",
        "VALIDATION_DIRECTORY = ... # TODO: Specify the validation data directory path\n",
        "TEST_DIRECTORY = ... # TODO: Specify the test data directory path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYsDXojA0Wm3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Define the paths to the directories\n",
        "directories = [\n",
        "    TRAINING_DIRECTORY,\n",
        "    VALIDATION_DIRECTORY,\n",
        "    TEST_DIRECTORY\n",
        "]\n",
        "\n",
        "# Define supported image file extensions\n",
        "supported_extensions = {\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\"}\n",
        "\n",
        "def delete_invalid_images(directory):\n",
        "    \"\"\"Goes through a directory and deletes any invalid or unsupported images.\"\"\"\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            # Check if the file has a supported extension\n",
        "            if not any(file.lower().endswith(ext) for ext in supported_extensions):\n",
        "                print(f\"Deleting unsupported file: {file_path}\")\n",
        "                os.remove(file_path)\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.load()  # Ensure the image content can be read\n",
        "                    if img.format not in [\"JPEG\", \"PNG\", \"GIF\", \"BMP\"]:\n",
        "                        raise IOError(\"Unsupported image format\")\n",
        "            except (IOError, SyntaxError, AttributeError) as e:\n",
        "                print(f\"Deleting invalid or corrupted image: {file_path}\")\n",
        "                os.remove(file_path)\n",
        "\n",
        "# Run the function for each directory\n",
        "for directory in directories:\n",
        "    delete_invalid_images(directory=directory)\n",
        "\n",
        "print(\"Invalid and unsupported image cleanup completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7IXjgBw1VW_"
      },
      "source": [
        "# Task 3\n",
        "\n",
        "1. Implement a function that visualizes 3 random examples per class from the training data to get a feel for the dataset.\n",
        "\n",
        "2. Run the function multiple times to get different images from the dataset.\n",
        "\n",
        "Hint: You can use whatever Python packages you like. `opencv` and `matplotlib` might be suitable choices. You can also check out the visualization functions in the second assignment notebooks of weeks 1 and 2 for reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pId_My4Y1kXI"
      },
      "outputs": [],
      "source": [
        "def visualize_random_images(directory_path, number_of_images=3):\n",
        "    image_files = [image_file for image_file in os.listdir(directory_path)]\n",
        "\n",
        "    # TODO: Implement the rest of the function\n",
        "    # YOUR CODE STARTS HERE\n",
        "\n",
        "\n",
        "\n",
        "    # YOUR CODE ENDS HERE\n",
        "\n",
        "class_directories = os.listdir(TRAINING_DIRECTORY)\n",
        "\n",
        "for class_directory in class_directories:\n",
        "  visualize_random_images(TRAINING_DIRECTORY + \"/\" + class_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psoxk096bqzM"
      },
      "source": [
        "# Task 4\n",
        "\n",
        "1. Choose an appropriate image size for the input images for an image classification task and set the values of the predefined constants `IMAGE_HEIGHT` and `IMAGE_WIDTH`.\n",
        "\n",
        "2. Load the training, validation and test datasets using the `image_dataset_from_directory` function shown in the first 7 minutes of [this video](https://www.youtube.com/watch?v=q7ZuZ8ZOErE). Specifically, set appropriate values for `label_mode`, `batch_size`, `image_size`, and `shuffle`. Each dataset should get a fixed `seed` of `123`.\n",
        "Check out the documentation for details:\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory\n",
        "\n",
        "    Hint: When selecting a value for `label_mode`, look at the loss function used below when compiling the model.\n",
        "\n",
        "3. Briefly explain for which of the training, validation and test datasets might be important to shuffle the data and why this is important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1v8Xkxvf5jE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulnhb0H1f5jH"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "IMAGE_HEIGHT = ... # TODO: Choose an appropriate image height\n",
        "IMAGE_WIDTH = ... # TODO: Choose an appropriate image width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74swqB1Nf5jI"
      },
      "outputs": [],
      "source": [
        "train_images = ... # TODO: Load the training dataset from the corresponding directory\n",
        "\n",
        "validation_images = ... # TODO: Load the validation dataset from the corresponding directory\n",
        "\n",
        "test_images = ... # TODO: Load the test dataset from the corresponding directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAdCBgsr1F6R"
      },
      "source": [
        "**Expected output:**  \n",
        "Found 14999 images belonging to 10 classes.  \n",
        "Found 3500 images belonging to 10 classes.  \n",
        "Found 1500 images belonging to 10 classes.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAwfSf2mbwZj"
      },
      "source": [
        "# Task 5\n",
        "\n",
        "In this exercise you will be given a predefined model architecture (except for the data-augmentation layers) that you should train using the data with and without the application of data augmentation and compare the results of the different models.\n",
        "\n",
        "1. Before defining the data-augmentation layers, train the model without data augmentation for at least 30 epochs (this may take some time). To do so, just run the code cell after the next one with the `data_augmentation_layers` commented out. Save a screenshot of the resulting accuracy and loss plots and judge the quality of the model. Also note the loss and accuracy of the model on the test set.\n",
        "\n",
        "2. Use the time that the first model is training to research and implement suitable data-augmentation layers. Choose 2 to 3 data augmentation techniques (other than rescaling) that might be suitable for the given dataset, and briefly explain why. Then train the model again, this time using data augmentation for the same number of epochs as the previous model. Compare the training and model quality of the two models.\n",
        "\n",
        "Take a look at the documentation for available image-augmentation layers in TensorFlow/Keras:\n",
        "https://keras.io/api/layers/preprocessing_layers/image_augmentation/\n",
        "\n",
        "You can also take inspiration from the augmentations used in the [video from the course material](https://www.youtube.com/watch?v=yke3zUGgQ-w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVa85yLAG7y7"
      },
      "outputs": [],
      "source": [
        "data_augmentation_layers = tf.keras.Sequential([\n",
        "    # TODO: Add data-augmentation layers\n",
        "    ...\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMG2AOP_f5jK"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input((IMAGE_HEIGHT, IMAGE_WIDTH, 3)),\n",
        "    tf.keras.layers.Rescaling(1/255),\n",
        "    \n",
        "    # TODO: Train the model with and without your data-augmentation layers by (un-)commenting the following line, and compare the performance\n",
        "    # data_augmentation_layers,\n",
        "    \n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjY9KixKf5jM"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    validation_data=validation_images,\n",
        "    epochs=30,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHLYrEAKOV-m"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the model training history\n",
        "def plot_training_history(history):\n",
        "    # Extracting accuracy and loss from the history object\n",
        "    training_accuracy = history.history[\"accuracy\"]\n",
        "    validation_accuracy = history.history[\"val_accuracy\"]\n",
        "    training_loss = history.history[\"loss\"]\n",
        "    validation_loss = history.history[\"val_loss\"]\n",
        "\n",
        "    # Setting up the number of epochs for the x-axis\n",
        "    epochs_range = range(1, len(training_accuracy) + 1)\n",
        "\n",
        "    # Plotting training and validation accuracy\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, training_accuracy, label=\"Training Accuracy\")\n",
        "    plt.plot(epochs_range, validation_accuracy, label=\"Validation Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Training and Validation Accuracy\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Plotting training and validation loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, training_loss, label=\"Training Loss\")\n",
        "    plt.plot(epochs_range, validation_loss, label=\"Validation Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training and Validation Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66z0TJ7wPWO8"
      },
      "outputs": [],
      "source": [
        "# Calculate loss and accuracy on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_images)\n",
        "print(f\"Test Accuracy: {test_accuracy} | Test Loss: {test_loss}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
