{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bte1ngygIzYD"
      },
      "source": [
        "# Assignment CNNs - Part 2: Transfer Learning Strategies with Fast Food Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq_Hc0aIW4-p"
      },
      "source": [
        "In this notebook, we will:\n",
        "1. Import and prepare the Fast Food Classification dataset\n",
        "2. Implement three different transfer learning strategies:\n",
        "   - Feature extraction (frozen pre-trained model)\n",
        "   - Fine-tuning last few layers\n",
        "   - Full fine-tuning\n",
        "3. Get experience on how sample size affects the strategy's performance\n",
        "4. Get experience of the impact of choosing the right/wrong learning rate\n",
        "5. Get experience with the different transfer learning strategies\n",
        "\n",
        "## 0. Introduction\n",
        "\n",
        "Transfer learning is a powerful technique that allows us to leverage pre-trained models for new tasks. However, different transfer learning strategies are suitable for different scenarios, particularly depending on:\n",
        "- Sample size of the target dataset\n",
        "- Similarity between source and target tasks\n",
        "- Available computational resources\n",
        "\n",
        "In this exercise, we'll explore different transfer learning strategies using the \"Fast Food Classification Dataset - V2\" from Kaggle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVcGvEOOf5i-"
      },
      "source": [
        "## 1. Data Import and Cleaning\n",
        "\n",
        "1. Download the [\"Fast Food Classification Dataset - V2\"](https://www.kaggle.com/datasets/utkarshsaxenadn/fast-food-classification-dataset/data) from Kaggle.\n",
        "\n",
        "2. Unzip and ensure that the dataset in Colab is structured as follows:\n",
        "\n",
        "```\n",
        "|\n",
        "|-- Fast Food Classification V2\n",
        "|   |-- TFRecords\n",
        "|   |-- Test\n",
        "|   |-- Train\n",
        "|   `-- Valid\n",
        "|-- sample_data\n",
        "`-- archive.zip\n",
        "```\n",
        "\n",
        "`Fast Food Classification V2` and `archive.zip` should be on the same level as the already existing `sample_data` directory from Colab. You can ignore the `TFRecords` subdirectory in the following tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5811abzgIiK",
        "outputId": "dd309578-150d-4f95-b2bd-7ee92f7becda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  820M  100  820M    0     0  76.5M      0  0:00:10  0:00:10 --:--:-- 89.7M\n"
          ]
        }
      ],
      "source": [
        "#!/bin/bash\n",
        "!curl -L -o archive.zip https://www.kaggle.com/api/v1/datasets/download/utkarshsaxenadn/fast-food-classification-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SytLYfaw6GyZ"
      },
      "outputs": [],
      "source": [
        "!unzip -q archive.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53kVJ_3nW4-v"
      },
      "source": [
        "3. Apply the provided `delete_invalid_images` function to check and remove any corrupted or invalid images in each of the three dataset directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRkFVeV2W4-w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Define the paths to the directories\n",
        "directories = [\n",
        "    \"Train\",\n",
        "    \"Valid\",\n",
        "    \"Test\"\n",
        "]\n",
        "\n",
        "# Define supported image file extensions\n",
        "supported_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp'}\n",
        "\n",
        "def delete_invalid_images(directory):\n",
        "    \"\"\"Goes through a directory and deletes any invalid or unsupported images.\"\"\"\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            # Check if the file has a supported extension\n",
        "            if not any(file.lower().endswith(ext) for ext in supported_extensions):\n",
        "                print(f\"Deleting unsupported file: {file_path}\")\n",
        "                os.remove(file_path)\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.load()  # Ensure the image content can be read\n",
        "                    if img.format not in [\"JPEG\", \"PNG\", \"GIF\", \"BMP\"]:\n",
        "                        raise IOError(\"Unsupported image format\")\n",
        "            except (IOError, SyntaxError, AttributeError) as e:\n",
        "                print(f\"Deleting invalid or corrupted image: {file_path}\")\n",
        "                os.remove(file_path)\n",
        "\n",
        "# Run the function for each directory\n",
        "for dir_path in directories:\n",
        "    delete_invalid_images(dir_path)\n",
        "\n",
        "print(\"Invalid and unsupported image cleanup completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBvTBaGh6SoJ"
      },
      "source": [
        "4. To reduce training time, only three classes are considered for the following training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRKkSOw16SEc"
      },
      "outputs": [],
      "source": [
        "# prompt: In each of the Train, Test, and Valid folder in the folder \"Fast Food Classification V2\" that were just unzipped, only keep the folders Taquito, Crispy Chicken, and Donut. Remove the others.\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the root directory of the dataset\n",
        "dataset_root = \"Fast Food Classification V2\"\n",
        "\n",
        "# Define the subdirectories (Train, Test, Valid)\n",
        "subdirectories = [\"Train\", \"Test\", \"Valid\"]\n",
        "\n",
        "# Define the classes to keep\n",
        "classes_to_keep = [\"Pizza\", \"Hot Dog\", \"Burger\"]\n",
        "\n",
        "# Loop through each subdirectory\n",
        "for subdir in subdirectories:\n",
        "  subdir_path = os.path.join(dataset_root, subdir)\n",
        "\n",
        "  # Loop through each folder (class) in the subdirectory\n",
        "  for class_folder in os.listdir(subdir_path):\n",
        "    class_folder_path = os.path.join(subdir_path, class_folder)\n",
        "\n",
        "    # Check if it's a directory and if it's not one of the classes to keep\n",
        "    if os.path.isdir(class_folder_path) and class_folder not in classes_to_keep:\n",
        "      print(f\"Removing folder: {class_folder_path}\")\n",
        "      shutil.rmtree(class_folder_path)\n",
        "\n",
        "print(\"Folder cleanup completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmyVO2AmW4-x"
      },
      "source": [
        "### Creation of Different Training Dataset Sizes\n",
        "\n",
        "   - Small: 50 images per class\n",
        "   - Medium: 200 images per class  \n",
        "   - Full: All available training images\n",
        "\n",
        "To reduce training time, only three classes are considered in the training.\n",
        "\n",
        "The validation and test sets will remain constant to ensure fair comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LUXtbLyXW4-x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Constants\n",
        "SMALL_SAMPLES = 50  # images per class\n",
        "MEDIUM_SAMPLES = 200 # images per class\n",
        "\n",
        "def create_sample_dataset(source_dir, target_dir, samples_per_class):\n",
        "    \"\"\"Creates a smaller dataset by randomly sampling from source directory\"\"\"\n",
        "    if os.path.exists(target_dir):\n",
        "        shutil.rmtree(target_dir)\n",
        "\n",
        "    # Create target directory\n",
        "    os.makedirs(target_dir)\n",
        "\n",
        "    # For each class directory\n",
        "    for class_dir in os.listdir(source_dir):\n",
        "        source_class_path = os.path.join(source_dir, class_dir)\n",
        "        target_class_path = os.path.join(target_dir, class_dir)\n",
        "\n",
        "        if os.path.isdir(source_class_path):\n",
        "            # Create class directory in target\n",
        "            os.makedirs(target_class_path)\n",
        "\n",
        "            # Get list of all images\n",
        "            images = os.listdir(source_class_path)\n",
        "\n",
        "            # Randomly sample specified number of images\n",
        "            selected_images = np.random.choice(\n",
        "                images,\n",
        "                size=min(samples_per_class, len(images)),\n",
        "                replace=False\n",
        "            )\n",
        "\n",
        "            # Copy selected images\n",
        "            for img in selected_images:\n",
        "                shutil.copy2(\n",
        "                    os.path.join(source_class_path, img),\n",
        "                    os.path.join(target_class_path, img)\n",
        "                )\n",
        "\n",
        "# Create sampled datasets\n",
        "create_sample_dataset(\"./Fast Food Classification V2/Train\", \"./Train_Small\", SMALL_SAMPLES)\n",
        "create_sample_dataset(\"./Fast Food Classification V2/Train\", \"./Train_Medium\", MEDIUM_SAMPLES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0xznoUZW4-y"
      },
      "source": [
        "## 2. Data Preprocessing\n",
        "\n",
        "1. Load the training, validation and test datasets using the `image_dataset_from_directory` function. Specifically, set appropriate values for `label_mode`, `batch_size`, `image_size` and `shuffle`. Each dataset should get a fixed `seed` of `42`.\n",
        "\n",
        "Checkout the documentation for details:\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6dKFV2IW4-z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Constants\n",
        "LABEL_MODE = None # TODO: Set appropriate value\n",
        "SEED = None # TODO: Choose a value\n",
        "IMAGE_HEIGHT = None # TODO: Set appropriate value\n",
        "IMAGE_WIDTH = None # TODO: Set appropriate value\n",
        "#Tip: Models that will be used with this data work usually best when the input images are of the same size as in the original training of the model.\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Load the small dataset\n",
        "train_data_small = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"Train_Small\",\n",
        "    label_mode=LABEL_MODE,\n",
        "    seed=SEED,  # Any fixed value works for reproducibility\n",
        "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=None #TODO: Set appropriate value\n",
        ")\n",
        "\n",
        "# Load the medium dataset\n",
        "train_data_medium = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"Train_Medium\",\n",
        "    label_mode=LABEL_MODE,\n",
        "    seed=SEED,  # Any fixed value works for reproducibility\n",
        "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=None #TODO: Set appropriate value\n",
        ")\n",
        "\n",
        "# Load the full dataset\n",
        "train_data_full = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"Fast Food Classification V2/Train\",\n",
        "    label_mode=LABEL_MODE,\n",
        "    seed=SEED,  # Any fixed value works for reproducibility\n",
        "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=None #TODO: Set appropriate value\n",
        ")\n",
        "\n",
        "# Load validation dataset\n",
        "validation_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"Fast Food Classification V2/Valid\",\n",
        "    label_mode='int',\n",
        "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=None #TODO: Set appropriate value\n",
        ")\n",
        "\n",
        "# Load the test dataset\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"Fast Food Classification V2/Test\",\n",
        "    label_mode='int',\n",
        "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=None #TODO: Set appropriate value\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dNVt06Gz828"
      },
      "source": [
        "## 3. Model Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkEKsc7CW4-0"
      },
      "source": [
        "Imports and Constants\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fpJXUjNZW4-0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "CLASSES = None # TODO: Set the number of classes\n",
        "IMAGE_HEIGHT = None # TODO: Choose an appropriate image height\n",
        "IMAGE_WIDTH = None # TODO: Choose an appropriate image width\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEFeJj34W4-0"
      },
      "source": [
        "### Feature Extraction\n",
        "\n",
        "1. Create a feature extraction model using the Inception V3 architecture.\n",
        "2. Freeze all layers of the base model.\n",
        "3. Add a new classification head with global average pooling, dropout, and a dense layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BYsDXojA0Wm3"
      },
      "outputs": [],
      "source": [
        "def create_feature_extraction_model():\n",
        "    \"\"\"Creates model with frozen base layers (feature extraction)\n",
        "\n",
        "    Discussion points:\n",
        "    1. Why might a simpler classification head be sufficient for transfer learning?\n",
        "    2. When would you consider adding more layers to the classification head?\n",
        "    3. How does the number of trainable parameters affect training with small datasets?\n",
        "    \"\"\"\n",
        "    # Load pre-trained InceptionV3 with correct input size\n",
        "    base_model = tf.keras.applications.InceptionV3(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3)\n",
        "    )\n",
        "\n",
        "    # Freeze all layers for feature extraction\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Simple classification head\n",
        "    # - GlobalAveragePooling2D reduces spatial dimensions\n",
        "    # - Final Dense layer maps to class probabilities\n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(CLASSES, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUK36M-NW4-1"
      },
      "source": [
        "### Fine-Tuning Last Few Layers\n",
        "\n",
        "1. Create a fine-tuning model using the Inception V3 architecture.\n",
        "2. Unfreeze the last few layers of the base model.\n",
        "3. Add a new classification head with global average pooling, dropout, and a dense layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_khIIV-zW4-1"
      },
      "outputs": [],
      "source": [
        "def create_fine_tuning_model():\n",
        "    \"\"\"Creates model with last few layers unfrozen for fine-tuning\"\"\"\n",
        "\n",
        "    # Load pre-trained InceptionV3 with correct input size\n",
        "    base_model = tf.keras.applications.InceptionV3(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3)\n",
        "    )\n",
        "\n",
        "    # Freeze all layers except last few blocks\n",
        "    base_model.trainable = True\n",
        "    for layer in base_model.layers[:-20]:  # Unfreeze last 20 layers\n",
        "        layer.trainable = False\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(CLASSES, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPRIXMlxW4-2"
      },
      "source": [
        "### Full Fine-Tuning\n",
        "\n",
        "1. Create a fine-tuning model using the Inception V3 architecture.\n",
        "2. Unfreeze all layers of the base model.\n",
        "3. Add a new classification head with global average pooling, dropout, and a dense layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "troP8F0VW4-2"
      },
      "outputs": [],
      "source": [
        "def create_full_fine_tuning_model():\n",
        "    \"\"\"Creates model with all layers unfrozen for full fine-tuning\"\"\"\n",
        "    base_model = tf.keras.applications.InceptionV3(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3)\n",
        "    )\n",
        "\n",
        "    # Make all layers trainable\n",
        "    base_model.trainable = True\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(1024, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(CLASSES, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVds6rKVW4-2"
      },
      "source": [
        "## 4. Model Training\n",
        "\n",
        "## Tasks\n",
        "\n",
        "1. Optimize two different models either using the same transfer learning strategy and two of the three datasets with different sizes or alternatively use one of the datasets with two different learning strategies.\n",
        "\n",
        "2. Find out what the arguments of the early stopping callback function mean.\n",
        "\n",
        "3. Choose appropriate learning rates.\n",
        "Tips for choosing it:\n",
        "- Start with the Default: Begin with the Adam optimizer's default learning rate of 0.001. This is often a good starting point.\n",
        "- When fine-tuning (especially full fine-tuning), consider using a smaller learning rate than the default. This helps prevent large updates to the pre-trained weights, which could disrupt the learned features. A learning rate of 1e-4 or 1e-5 is a good starting point.\n",
        "- The best learning rate will depend on the specific dataset and model. Experiment with different values and observe the training and validation performance. Look for a learning rate that allows the model to converge smoothly without overshooting or getting stuck in a local minimum.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEvwEFNfSRtR"
      },
      "source": [
        "### Example for Training of the Feature Extraction Model with the Small Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dN9XU7xYdW2n"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = None # Choose appropriately\n",
        "\n",
        "# Settings for the Feature Extraction Model on the small dataset\n",
        "model_feature_extraction_small = create_feature_extraction_model()\n",
        "model_feature_extraction_small.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "# Model Summary\n",
        "model_feature_extraction_small.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoHtBg-0W4-2"
      },
      "outputs": [],
      "source": [
        "# Model Training\n",
        "history_feature_extraction_small = model_feature_extraction_small.fit(\n",
        "    train_data_small,\n",
        "    validation_data=validation_data,\n",
        "    epochs=100,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=3,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
